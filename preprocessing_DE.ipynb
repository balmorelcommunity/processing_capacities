{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Capacities Germany for Balmorel from OPSD\n",
    "\n",
    ">__*Python version 3.6*__\n",
    ">\n",
    "> Author: [tilseb](tilseb@dtu.dk)\n",
    ">\n",
    "> Date: 2018-05-29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "- Script setup\n",
    "- Make directories\n",
    "- Download data from opsd\n",
    "- Read input data\n",
    "- Suspect powerplants\n",
    "- Specific technology naming translation\n",
    "- Heat-only re-aggregation\n",
    "- Balmorel wording\n",
    "- Lifetime\n",
    "- Balmorel regions\n",
    "- Capacities\n",
    "- Temporary storing of dataframes\n",
    "- Aggregation\n",
    "- Output: district heating\n",
    "- Efficiency\n",
    "- Grouping: technology, efficiency and region\n",
    "- Clean-up for output\n",
    "- Write output files\n",
    "- Plotting of fuel stock\n",
    "- Clean-up for final output\n",
    "- G output\n",
    "- GKFX output\n",
    "- CCC, RRR, AAA output\n",
    "- Comparison of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import pickle\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make input and ouput directories\n",
    "dirs = ['input', 'output']\n",
    "for i in dirs:\n",
    "    if not os.path.isdir(i):\n",
    "        os.makedirs(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data from OPSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventional Power Plants\n",
    "Source: https://data.open-power-system-data.org/conventional_power_plants/\n",
    "\n",
    "Download: *conventional_power_plants_DE.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download opsd conventional data\n",
    "url = 'https://data.open-power-system-data.org/conventional_power_plants/2018-02-27/conventional_power_plants_DE.csv'  \n",
    "filename = 'conventionals.csv'\n",
    "filepath = os.path.join('input', filename)\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    urllib.request.urlretrieve(url, filepath)\n",
    "else:\n",
    "    print('Using local file from ' + filepath + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renewable Power Plants\n",
    "Source: https://data.open-power-system-data.org/renewable_power_plants/\n",
    "\n",
    "Download: *renewable_power_plants_DE.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download opsd conventional data\n",
    "url = 'https://data.open-power-system-data.org/renewable_power_plants/2018-03-08/renewable_power_plants_DE.csv'  \n",
    "filename = 'renewables.csv'\n",
    "filepath = os.path.join('input', filename)\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    urllib.request.urlretrieve(url, filepath)\n",
    "else:\n",
    "    print('Using local file from ' + filepath + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventional Power Plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read conventional power plants\n",
    "con = pd.read_csv('input/conventionals.csv',\n",
    "                  encoding='utf8',\n",
    "                  header=0)\n",
    "\n",
    "# Fill empty cells in the chp column with 'no'\n",
    "con.chp.fillna(value='no', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renwable Power Plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read renewable capacities\n",
    "ren = pd.read_csv('input/renewables.csv',\n",
    "                  encoding='UTF8',\n",
    "                  header=0,\n",
    "                  parse_dates=[1],\n",
    "                  dtype={'postcode': str},\n",
    "                  low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Technology Name Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read specific tec translation\n",
    "tec_translation = pd.read_csv('input/tec_acronyms_spec.csv',\n",
    "                              encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technology Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read acronyms for technologies\n",
    "tec = pd.read_csv('input/tec_acronyms.csv',\n",
    "                  encoding='utf8',\n",
    "                  header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuel Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read acronyms for fuels\n",
    "fuel = pd.read_csv('input/fuel_acronyms.csv',\n",
    "                   encoding='UTF8',\n",
    "                   header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lifetime\n",
    "1. Source: https://ens.dk/sites/ens.dk/files/Analyser/update_-_technology_data_catalogue_for_energy_plants_-_aug_2016.pdf\n",
    "> Assumption: It's the technical lifetime and depending on the commissioning year.\n",
    "\n",
    "2. Source: Nuclear phase-out data, tab. 22 on p. 172: https://www.iea.org/publications/freepublications/publication/Germany2013_free.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read lifetime data for power plants\n",
    "lifetime = pd.read_csv('input/lifetimes.csv',\n",
    "                       encoding='UTF8',\n",
    "                       header=0)\n",
    "\n",
    "# Set dtype of the years to float\n",
    "lifetime.loc['2015':'2050'] = lifetime.loc['2015':'2050'].astype(float)\n",
    "\n",
    "\n",
    "# Read nuclear lifetime data\n",
    "lifetime_nuclear = pd.read_csv('input/lifetimes_nuclear.csv',\n",
    "                               encoding='UTF8',\n",
    "                               header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regions\n",
    "Source: Data for postal codes to federal state translation: https://www.suche-postleitzahl.org/downloads\n",
    "\n",
    "Download: *zuordnung_plz_ort*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the german address-postcode to grid region to balmorel region translation\n",
    "region_zip_grid = pd.read_csv('input/region_zip_grid.csv',\n",
    "                              encoding='UTF8',\n",
    "                              header=0,\n",
    "                              dtype={'zip_code': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the non-german address-postcode to grid region to balmorel region translation\n",
    "region_zip_grid_non_DE = pd.read_csv('input/region_zip_grid_international.csv',\n",
    "                                     encoding='UTF8',\n",
    "                                     header=0,\n",
    "                                     dtype={'zip_code': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the region-choice file for balmorel-region aggregation\n",
    "region_agg = pd.read_csv('input/region_aggregation.csv',\n",
    "                         encoding='UTF8',\n",
    "                         header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the federal-state to address-postcode translation\n",
    "region_fs_zip = pd.read_csv('input/region_zip_federalstate.csv',\n",
    "                            encoding='UTF8',\n",
    "                            header=0,\n",
    "                            dtype={'zip_code': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat Only\n",
    "1. Source: https://www.agfw.de/zahlen-und-statistiken/agfw-hauptbericht/\n",
    "\n",
    ">Download: *Download der Ã¶ffentlichen Variante Hauptbericht 2016*\n",
    "\n",
    "2. Source: Data for total dh demand: https://www.ag-energiebilanzen.de/\n",
    "\n",
    ">Download: *Energieverbrauch in Deutschland im Jahr 2017* (pg. 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read installed capacities of heat only plants\n",
    "ho_cap = pd.read_csv('input/cap_heatonly.csv',\n",
    "                     encoding='UTF8',\n",
    "                     header=0,\n",
    "                     skiprows=[1])\n",
    "\n",
    "# Read fuel shares of heat only plants\n",
    "ho_fuel = pd.read_csv('input/fuel_heatonly.csv',\n",
    "                      encoding='UTF8',\n",
    "                      header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offshore\n",
    "\n",
    "Source: http://www.erneuerbare-energien.de/EE/Navigation/DE/Technologien/Windenergie-auf-See/Offshore-Projekte/Netzanbindungen/netzanbindungen.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifier\n",
    "\n",
    "In order to extract missing information on the grid connection points of offshore wind farms in the north sea. Therefore a eeg_id_identifier filters the eeg_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read eeg_id_identifier\n",
    "offshore_id = pd.read_csv('input/offshore_identifier.csv',\n",
    "                          encoding='UTF8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Planned Capacities\n",
    "\n",
    "Adding offshore capacities to the opsd_ren table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read planned offshore capacities\n",
    "off_fut = pd.read_csv('input/cap_offshore_planned.csv',\n",
    "                      encoding='UTF8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors\n",
    "\n",
    "Assign a color to each fuel for the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read color data\n",
    "colors = pd.read_csv('input/fuel_colors.csv',\n",
    "                     encoding='UTF8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suspect Powerplants\n",
    "A powerplant is considered a suspect entry, when its comment cell is NOT empty. Those entries wont be considered.\n",
    "\n",
    "Check https://github.com/Open-Power-System-Data/renewable_power_plants/blob/2017-06-26/main.ipynb (*5.3: validation Marker*) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check, whether suspicios entries exist for opsd_con\n",
    "con.comment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check, whether suspicios entries exist for opsd_ren\n",
    "ren.comment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Locate suspect entries for opsd_con and opsd_ren\n",
    "idx_con_suspect = con[con.comment.isnull() == False].index\n",
    "idx_ren_suspect = ren[ren.comment.isnull() == False].index\n",
    "\n",
    "# Create new opsd_ren dataframe without suspect entries\n",
    "con.drop(idx_con_suspect, inplace=True)\n",
    "ren.drop(idx_ren_suspect, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check, whether suspicios entries exist for the clean opsd_con\n",
    "con.comment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check, whether suspicios entries exist for the clean opsd_ren\n",
    "ren.comment.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Technology Naming Translation\n",
    "\n",
    "Some technology types have to be translated to a different one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a new columns in opsd_con\n",
    "con['new_technology'] = con.id\n",
    "\n",
    "# Make a dictionary from id to opsd_technology_new\n",
    "dict_tec_trans = tec_translation[['id','opsd_technology_new']].set_index('id')['opsd_technology_new'].to_dict()\n",
    "\n",
    "# Apply the dict_tec_trans\n",
    "con['new_technology'].replace(dict_tec_trans, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Over-write old by new tachnologies, if a technology name is in the new_technology column\n",
    "con['technology'] = np.where(con.id != con.new_technology, con.new_technology, con.technology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat-Only Re-Aggregation\n",
    "Data about heat-only powerplants comes from a different source than the opsd data. The information is allready aggregated on federal state level, which differs from the grid_id aggregation. Thus, the aggregated capacities are partitioned evenly on postcode level and subsequently re-aggregated to the grid_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a new column in ho_fuel with vaules of the federal state column\n",
    "ho_fuel['capacity'] = ho_fuel['federal_state']\n",
    "\n",
    "# Make a dictionary from federal state to fuel-input-capacity\n",
    "ho_cap_dict = ho_cap[['federal_state','ho_capacity']].set_index('federal_state')['ho_capacity'].to_dict()\n",
    "\n",
    "\n",
    "# Replace the federal state values of the fuel input capacity column by the fuel input capacity\n",
    "ho_fuel['capacity'].replace(ho_cap_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a new column with the fuel capacity share\n",
    "ho_fuel['fuel_capacity_share'] = ho_fuel['average_efficiency_2017'] * ho_fuel['fuel_share_gross']\n",
    "ho_fuel['fuel_capacity_share'] = ho_fuel.groupby(['federal_state'])['fuel_capacity_share'].transform(lambda x: x / x.sum())\n",
    "ho_fuel['fuel_capacity_share'] = ho_fuel['fuel_capacity_share'] * ho_fuel['capacity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge ho_fuel and the federal state to postcode translation to a new dataframe called ho\n",
    "ho = region_fs_zip.merge(ho_fuel, how='outer', left_on='federal_state', right_on='federal_state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate capacity share for each postcode\n",
    "ho['zip_capacity_share'] = ho.groupby(['federal_state',\n",
    "                                       'balmorel_fuel'])['fuel_capacity_share'].transform(lambda x: x.mean() / x.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop rows with nans in the zip_capacity_share column\n",
    "ho.dropna(subset=['zip_capacity_share'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### District Heating Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new dataframe for dh demand\n",
    "dh = ho_cap[['federal_state','net_dh_demand']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge dh and the federal state to postcode translation to a new dataframe called again dh\n",
    "dh = region_fs_zip.merge(dh, how='outer', left_on='federal_state', right_on='federal_state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate dh demand share for each postcode\n",
    "dh['zip_dh_share'] = dh.groupby(['federal_state'])['net_dh_demand'].transform(lambda x: x.mean() / x.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop rows with nans in the zip_dh_share column\n",
    "dh.dropna(subset=['zip_dh_share'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balmorel Wording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new ren and con columns in the tec_acronyms table\n",
    "tec['tec_con_dict'] = tec['opsd_technology_conventional']\n",
    "tec['tec_ren_dict'] = tec['opsd_technology_renewable']\n",
    "\n",
    "# Combine the information about technology and chp for con\n",
    "tec['tec_con_dict'] = tec['tec_con_dict'].astype(str).str.cat(tec['opsd_chp'].astype(str), sep=' chp_')\n",
    "tec['tec_ren_dict'] = tec['tec_ren_dict'].astype(str).str.cat(tec['opsd_chp'].astype(str), sep=' chp_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conventional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new column in the opsd_con table\n",
    "con['balmorel_tec_group'] = con['technology']\n",
    "con['balmorel_tec_type'] = con['technology']\n",
    "\n",
    "# Combine the information about technology and chp\n",
    "con['balmorel_tec_group'] = con['balmorel_tec_group'].astype(str).str.cat(con['chp'].astype(str), sep=' chp_')\n",
    "con['balmorel_tec_type'] = con['balmorel_tec_type'].astype(str).str.cat(con['chp'].astype(str), sep=' chp_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make an index for the ones that have a technology in the opsd_technology_conventional column in tec_acronyms\n",
    "idx_tec_con = tec[(tec['opsd_technology_conventional'].notnull())].index\n",
    "\n",
    "# Reduce the table for the dictionary to these ones\n",
    "tec_con_no_nan = tec.loc[idx_tec_con,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a conventional dictionary\n",
    "dict_tec_group_con = tec_con_no_nan[['tec_con_dict','balmorel_tec_group']].set_index('tec_con_dict')['balmorel_tec_group'].to_dict()\n",
    "dict_tec_type_con = tec_con_no_nan[['tec_con_dict','balmorel_tec_type']].set_index('tec_con_dict')['balmorel_tec_type'].to_dict()\n",
    "\n",
    "# Replace in the balmorel_technology column in opsd_con the dict_tec_con by the balmorel acronym\n",
    "con['balmorel_tec_group'].replace(dict_tec_group_con, inplace=True)\n",
    "con['balmorel_tec_type'].replace(dict_tec_type_con, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renewable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign the energy-source-level 2 to empty cells in the technology column\n",
    "ren.loc[ren.technology.isnull()==True, 'technology'] = ren['energy_source_level_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new column in the opsd_ren table\n",
    "ren['balmorel_tec_group'] = ren['technology']\n",
    "ren['balmorel_tec_type'] = ren['technology']\n",
    "\n",
    "# Make a new column for information about chp\n",
    "ren.loc[(ren.thermal_capacity > 0) & (ren.electrical_capacity > 0), 'opsd_chp'] = 'yes'\n",
    "ren.loc[ren.opsd_chp != 'yes', 'opsd_chp'] = 'no'\n",
    "\n",
    "# Combine the information about technology and chp\n",
    "ren['balmorel_tec_group'] = ren['balmorel_tec_group'].astype(str).str.cat(ren['opsd_chp'].astype(str), sep=' chp_')\n",
    "ren['balmorel_tec_type'] = ren['balmorel_tec_type'].astype(str).str.cat(ren['opsd_chp'].astype(str), sep=' chp_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make an index for the ones that have a technology in the opsd_technology_renewable column in tec_acronyms\n",
    "idx_tec_ren = tec[(tec['opsd_technology_renewable'].notnull())].index\n",
    "\n",
    "# Reduce the table for the dictionary to these ones\n",
    "tec_ren_no_nan = tec.loc[idx_tec_ren,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a renewable dictionary\n",
    "dict_tec_group_ren = tec_ren_no_nan[['tec_ren_dict','balmorel_tec_group']].set_index('tec_ren_dict')['balmorel_tec_group'].to_dict()\n",
    "dict_tec_type_ren = tec_ren_no_nan[['tec_ren_dict','balmorel_tec_type']].set_index('tec_ren_dict')['balmorel_tec_type'].to_dict()\n",
    "\n",
    "# Replace in the balmorel_technology column in opsd_ren the dict_tec_ren by the balmorel acronym\n",
    "ren['balmorel_tec_group'].replace(dict_tec_group_ren, inplace=True)\n",
    "ren['balmorel_tec_type'].replace(dict_tec_type_ren, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a new column in off_fut\n",
    "off_fut['balmorel_tec_group'] = 'Offshore chp_no'\n",
    "off_fut['balmorel_tec_type'] = 'Offshore chp_no'\n",
    "\n",
    "# Replace in the values by the balmorel acronyms\n",
    "off_fut['balmorel_tec_group'].replace(dict_tec_group_ren, inplace=True)\n",
    "off_fut['balmorel_tec_type'].replace(dict_tec_type_ren, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new column in the fuel_acronyms table\n",
    "fuel['fuel_dict'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill nans in the fuel_acronyms table with the least high energy source level\n",
    "for i in range(2, fuel.shape[1]):\n",
    "    fuel[fuel.columns[i]].fillna(value=fuel[fuel.columns[i - 1]], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the fuel dictionary\n",
    "dict_fuel = fuel[['fuel_dict','balmorel_fuel']].set_index('fuel_dict')['balmorel_fuel'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conventional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill nans in energy source level 2 in the opsd_con table with energy source level 1\n",
    "con['energy_source_level_2'].fillna(value=con['energy_source_level_1'], inplace=True)\n",
    "\n",
    "# Fill nans in energy source level 3 in the opsd_con table with energy source level 2\n",
    "con['energy_source_level_3'].fillna(value=con['energy_source_level_2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a new column in the conventional table\n",
    "con['balmorel_fuel'] = con['energy_source_level_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace all missing values with the initital opsd_fuel\n",
    "con['balmorel_fuel'].fillna(value=con['fuel'], inplace=True)\n",
    "\n",
    "# Replace in the opsd_con table the fuel_dict column by the balmorel acronyms\n",
    "con['balmorel_fuel'].replace(dict_fuel, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete the rows with nans in the balmorel_fuel column for opsd_con\n",
    "con = con.dropna(subset=['balmorel_fuel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renewable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill nans in energy source level 2 in the opsd_ren table with energy source level 1\n",
    "ren['energy_source_level_2'].fillna(value=ren['energy_source_level_1'], inplace=True)\n",
    "\n",
    "# Fill nans in energy source level 3 in the opsd_ren table with energy source level 2\n",
    "ren['energy_source_level_3'].fillna(value=ren['energy_source_level_2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a new column in the renewable table\n",
    "ren['balmorel_fuel'] = ren['energy_source_level_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace in the opsd_ren table the fuel_dict column by the balmorel acronyms\n",
    "ren = ren.assign(balmorel_fuel = ren.loc[:,'balmorel_fuel'].map(lambda x: dict_fuel.get(x, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete the rows with nans in the balmorel_fuel column for opsd_ren\n",
    "ren = ren.dropna(subset=['balmorel_fuel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Offshore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a new column in off_fut\n",
    "off_fut['balmorel_fuel'] = 'Wind'\n",
    "\n",
    "# Replace the values by the balmorel acronyms\n",
    "off_fut['balmorel_fuel'].replace(dict_fuel, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pumped storages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change fuel name for pumped hydro from WTR to ELEC\n",
    "con['balmorel_fuel'] = np.where(con['balmorel_tec_type'] == 'PMP', 'ELEC', con['balmorel_fuel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a new column in the lifetime table\n",
    "lifetime['lifetime_con_dict'] = lifetime['opsd_technology_conventional']\n",
    "\n",
    "# Combine the information about technology, chp and fuel\n",
    "lifetime['lifetime_con_dict'] = lifetime['lifetime_con_dict'].astype(str).str.cat(lifetime.opsd_chp.astype(str), sep=' chp_')\n",
    "lifetime['lifetime_con_dict'] = lifetime['lifetime_con_dict'].astype(str).str.cat(lifetime.opsd_fuel.astype(str), sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make an index for the ones that have a technology in the opsd_technology_conventional column in opsd_con\n",
    "idx_lifetime_con = lifetime[(lifetime['opsd_technology_conventional'].notnull())].index\n",
    "\n",
    "# Reduce the table for the dictionary to these ones\n",
    "lifetime_con = lifetime.loc[idx_lifetime_con,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the conventional lifetime dictionary\n",
    "con_dict_lifetime = lifetime_con[['lifetime_con_dict',\n",
    "                                  'lifetime_2015']].set_index('lifetime_con_dict')['lifetime_2015'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new columns in the opsd_con table and combine the information about technology, chp and fuel\n",
    "con['lifetime_2015'] = con['technology']\n",
    "con['lifetime_2015'] = con['lifetime_2015'].astype(str).str.cat(con['chp'].astype(str), sep=' chp_')\n",
    "con['lifetime_2015'] = con['lifetime_2015'].astype(str).str.cat(con['fuel'].astype(str), sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace in the opsd_con table the lt columns by the conventional lifetime dictionary\n",
    "con['lifetime_2015'].replace(con_dict_lifetime, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill shutdown column with sum of commissioning year and the technical lifetime expectency\n",
    "con = con.assign(shutdown = con['commissioned'] + con['lifetime_2015'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special Case Old Plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Artificial lifetime prolongation for old plants: shutdown before 2016\n",
    "# The earliest shutdown daten and 2016 unfold an interval that is cut into ten equal sub-intervals\n",
    "# to classify the powerplants new shutdown date: 1st -> 2019, 2nd -> 2020, ... , 10th -> 2029\n",
    "j = 2019\n",
    "for i in np.linspace(min(con.shutdown), 2016, 11, endpoint=True).round(0).astype(int):\n",
    "    con.loc[(con['shutdown'] < i), 'shutdown'] = j\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special Case Coal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Artificial lifetime shortening for new coal fired powerplants: commissioned from 2010 onwards\n",
    "# Motivation: no coal from 2050 onwards\n",
    "# 2010 and the latest commission date unfold an interval that is cut into ten equal sub-intervals\n",
    "# To classify the powerplants new shutdown date: 1st -> 2040, 2nd -> 2041, ... , 10th -> 2049\n",
    "j = 2040\n",
    "for i in np.linspace(2009, max(con.commissioned), 10, endpoint=True).round(0).astype(int):\n",
    "    con.loc[(con['commissioned'] > i) & (con['balmorel_fuel'] == 'COAL'), 'shutdown'] = j\n",
    "    con.loc[(con['commissioned'] > i) & (con['balmorel_fuel'] == 'LIGN'), 'shutdown'] = j\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nuclear Phase-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the nuclear powerplants in the opsd_con table fill the shutdown column with their id's\n",
    "con['shutdown'] = np.where(con['fuel'] == 'Nuclear', con['id'], con['shutdown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a nuclear lifetime dictionary\n",
    "nuclear_dict = lifetime_nuclear[['opsd_id','balmorel_shutdown']].set_index('opsd_id')['balmorel_shutdown'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace the nuclear powerplant ids in the shutdown column with the phase-out date of the nuclear dictionary\n",
    "con['shutdown'].replace(nuclear_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renewable Lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a new column in the lifetime table\n",
    "lifetime['lifetime_ren_dict'] = lifetime['opsd_technology_renewable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make an index for the ones that have a technology in the opsd_technology_renewable column in opsd_ren\n",
    "idx_lifetime_ren = lifetime[(lifetime['opsd_technology_renewable'].notnull())].index\n",
    "\n",
    "# Reduce the table for the dictionary to these ones\n",
    "lifetime_ren = lifetime.loc[idx_lifetime_ren,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the renewable lifetime dictionary\n",
    "ren_dict_lifetime = lifetime_ren[['lifetime_ren_dict',\n",
    "                                  'lifetime_2015']].set_index('lifetime_ren_dict')['lifetime_2015'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new a column and replace in the opsd_ren table the lt columns by the renewable lifetime dictionary\n",
    "ren = ren.assign(lifetime_2015 = ren.loc[:,'technology'].map(lambda x: ren_dict_lifetime.get(x, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create commissioned and shutdown columns in opsd_ren\n",
    "ren['commissioned'] = pd.DatetimeIndex(ren['commissioning_date']).year\n",
    "ren['shutdown'] = pd.DatetimeIndex(ren['decommissioning_date']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill the renewable shutdown columns with regard to the year of commissioning\n",
    "ren['shutdown'] = ren['shutdown'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill shutdown column with sum of commissioning year and the technical lifetime expectency\n",
    "ren = ren.assign(shutdown = ren['commissioned'] + ren['lifetime_2015'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a new technology and lifetime columns in off_fut\n",
    "off_fut['technology'] = 'Offshore'\n",
    "off_fut['lifetime_2015'] = 'Offshore'\n",
    "\n",
    "# Replace the values by the renewable lifetime dictionary\n",
    "off_fut['lifetime_2015'].replace(ren_dict_lifetime, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create commissioned and shutdown columns in off_fut\n",
    "off_fut['commissioned'] = off_fut['commissioning_year']\n",
    "off_fut['shutdown'] = off_fut['commissioning_year']\n",
    "\n",
    "# Fill shutdown column with sum of commissioning year and the technical lifetime expectency\n",
    "off_fut = off_fut.assign(shutdown = off_fut['commissioned'] + off_fut['lifetime_2015'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat-Only\n",
    "\n",
    "The lifetime of heat only powerplants (boilers) is estimated to 40 years. It is directly applied in the **capacity** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balmorel Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to find nearest postcode neighbours, if postcode is missing in the translation table\n",
    "array = np.array(pd.to_numeric(region_zip_grid['zip_code']))\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    x = int(value)\n",
    "    idx = (np.abs(array - x)).argmin()\n",
    "    return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make dictionaries from postcodes for DE and non_DE to grid region\n",
    "dict_zip_grid = region_zip_grid[['zip_code','grid_id']].set_index('zip_code')['grid_id'].to_dict()\n",
    "dict_zip_grid_non_DE = region_zip_grid_non_DE[['zip_code','grid_id']].set_index('zip_code')['grid_id'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign not existing german postcodes in opsd_con to the nearest postcode number of the translation dictionary\n",
    "con_values = con[(con['postcode'].isin(dict_zip_grid) == False) & (con['postcode'].str.isdigit() == True)].postcode\n",
    "           \n",
    "for i in con_values:\n",
    "    con.loc[con.postcode == i, 'postcode'] = find_nearest(array, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new column in opsd_con\n",
    "con['balmorel_region'] = con['postcode'].apply(str)\n",
    "\n",
    "# Replace in the balmorel_region column in opsd_con the zip-code by the balmorel region for both DE and international\n",
    "con = con.assign(balmorel_region = con.loc[:,'balmorel_region'].map(lambda x: dict_zip_grid.get(x, x)))\n",
    "con = con.assign(balmorel_region = con.loc[:,'balmorel_region'].map(lambda x: dict_zip_grid_non_DE.get(x, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renewable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new column in opsd_ren\n",
    "ren = ren.assign(balmorel_region = ren.loc[:,'postcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new column in off_fut\n",
    "off_fut = off_fut.assign(balmorel_region = off_fut.loc[:,'postcode'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Offshore\n",
    "Wind power plants get postcode of their land connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting information form the eeg_id column of opsd_ren, in order to assign the correct postcode\n",
    "for i in offshore_id.eeg_id_identifier:\n",
    "    ren.loc[(ren.technology == 'Offshore') & (ren['eeg_id'].str.contains(i)==True), 'postcode'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make dictionary from egg_id_identifier to postcodes\n",
    "dict_offshore = offshore_id[['eeg_id_identifier','postcode']].set_index('eeg_id_identifier')['postcode'].to_dict()\n",
    "\n",
    "# Replace in the postcode column in opsd_ren the eeg_id_identifier by the respective postcode\n",
    "ren = ren.assign(balmorel_region = ren.loc[:,'postcode'].map(lambda x: dict_offshore.get(x, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace in the balmorel_region column in opsd_ren the zip-code by the balmorel region\n",
    "ren = ren.assign(balmorel_region = ren.loc[:,'balmorel_region'].map(lambda x: dict_zip_grid.get(x, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a dataframe from opsd_ren containing the powerplants with missing grid id\n",
    "ren_no_grid_id = ren[(ren['postcode'].astype(str).isin(dict_zip_grid) == False) &\n",
    "                     (ren['postcode'].astype(str).str.isdigit() == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign not existing german postcodes in the ren_no_grid_id to the nearest postcode of the translation dictionary\n",
    "for i in ren_no_grid_id['postcode'].unique():\n",
    "    ren_no_grid_id.loc[ren_no_grid_id.postcode == i, 'postcode'] = find_nearest(array, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new column in the ren_no_grid_id table\n",
    "ren_no_grid_id = ren_no_grid_id.assign(balmorel_region = ren_no_grid_id.loc[:,'postcode'].apply(str))\n",
    "\n",
    "# Replace in the balmorel_region column in ren_no_gird_id the zip-code by the balmorel region\n",
    "ren_no_grid_id = ren_no_grid_id.assign(balmorel_region = ren_no_grid_id.loc[:,'balmorel_region'].map(lambda x: dict_zip_grid.get(x, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trim the opsd_ren to the rows that have a grid_id\n",
    "ren = ren[(ren.postcode.astype(str).isin(dict_zip_grid) == True)]\n",
    "\n",
    "#Aappend the two ren dataframes\n",
    "ren = ren.append(ren_no_grid_id, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop rows without grid_id\n",
    "ren = ren[ren['balmorel_region'].isin(region_agg['grid_id'].astype(object))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Offshore Planned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign not existing german postcodes in off_fut to the nearest postcode of the translation dictionary\n",
    "for i in off_fut['postcode'].unique():\n",
    "    off_fut.loc[off_fut['postcode'] == i, 'postcode'] = find_nearest(array, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace in the balmorel_region column in off_fut the zip-code by the balmorel region\n",
    "off_fut['balmorel_region'].replace(dict_zip_grid, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heat-Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new column in the heat_only table\n",
    "ho['balmorel_region'] = ho['zip_code']\n",
    "\n",
    "# Replace in the balmorel_region column in heat_only the zip-code by the balmorel region\n",
    "ho = ho.assign(balmorel_region = ho.loc[:,'balmorel_region'].map(lambda x: dict_zip_grid.get(x, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group ho by balmoerl region and balmorel fuel and aggregate the sum of the capacity shares to it\n",
    "ho = ho.groupby(['balmorel_region','balmorel_fuel']).agg({'zip_capacity_share': ['sum']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-arrange the grouped table back into a pandas dataframe \n",
    "ho = pd.DataFrame(ho)\n",
    "ho.reset_index(inplace=True)\n",
    "ho['balmorel_region'] = ho['balmorel_region'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### District Heating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new column in the dh table\n",
    "dh['balmorel_region'] = dh['zip_code']\n",
    "\n",
    "# Replace in the balmorel_region column in dh the zip-code by the balmorel region\n",
    "dh = dh.assign(balmorel_region = dh.loc[:,'balmorel_region'].map(lambda x: dict_zip_grid.get(x, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group dh by balmorel region and aggregate the sum of the dh shares to it\n",
    "dh = dh.groupby(['balmorel_region']).agg({'zip_dh_share': ['sum']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-arrange the grouped table back into a pandas dataframe \n",
    "dh = pd.DataFrame(dh)\n",
    "dh.reset_index(inplace=True)\n",
    "dh.columns = dh.columns.droplevel(1)\n",
    "dh['balmorel_region'] = dh['balmorel_region'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capacities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage Technologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Electricity Storages\n",
    "Information on (un-)loading hours of lagre scale battery systems by STEAG: https://www.energystorageexchange.org/projects/global_search?q=steag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Give an average loading duration in hours for large scale battery storages\n",
    "average_loading_es = 1.5\n",
    "\n",
    "# Multiply the rated power by the (un-)loading duration: MW -> MWh\n",
    "con['capacity_net_bnetza'] = np.where(con['balmorel_tec_group'] == 'ES',\n",
    "                                      con['capacity_net_bnetza'] * average_loading_es,\n",
    "                                      con['capacity_net_bnetza'])\n",
    "ren['electrical_capacity'] = np.where(ren['balmorel_tec_group'] == 'ES',\n",
    "                                      ren['electrical_capacity'] * average_loading_es,\n",
    "                                      ren['electrical_capacity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pumped Storages\n",
    "Information on (un-)loading hours of pumped storages in Germany: http://www.diw.de/sixcms/detail.php?id=diw_01.c.424588.de (pg. 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Give an average loading duration in hours for german pump storages\n",
    "average_loading_pmp = 8\n",
    "\n",
    "# Multiply the rated power by the (un-)loading duration: MW -> MWh\n",
    "con['capacity_net_bnetza'] = np.where(con['balmorel_tec_type'] == 'PMP',\n",
    "                                      con['capacity_net_bnetza'] * average_loading_pmp,\n",
    "                                      con['capacity_net_bnetza'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capacity Per Year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a new capacity column in opsd_con, opsd_ren and ho\n",
    "con['capacity'] = con['capacity_net_bnetza']\n",
    "ren['capacity'] = ren['electrical_capacity']\n",
    "ho['capacity'] = ho['zip_capacity_share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill empty commissioned and shutdown cells with zero in opsd_con\n",
    "con.commissioned.fillna(value=0, inplace=True)\n",
    "con.shutdown.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill empty commissioned and shutdown cells with zero in opsd_ren\n",
    "ren.commissioned.fillna(value=0, inplace=True)\n",
    "ren.shutdown.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the capacities of each power plant in the new year columns - from 2012 to 2050.\n",
    "# Check, whether the year in the column list exceeds the shutdown date. \n",
    "# Then the power plant capacity goes down to zero.\n",
    "years = np.arange(2012, 2051, 1, dtype=int)\n",
    "\n",
    "for i in years:\n",
    "    i = int(i)\n",
    "    \n",
    "    con['{}'.format(i)] = np.where((con['shutdown'].astype(int) >= i) &\n",
    "                                   (con['commissioned'].astype(int) <= i), con['capacity'], 0)\n",
    "    \n",
    "    ren['{}'.format(i)] = np.where((ren['shutdown'].astype(int) >= i) &\n",
    "                                   (ren['commissioned'].astype(int) <= i), ren['capacity'], 0)\n",
    "    \n",
    "    off_fut['{}'.format(i)] = np.where((off_fut['shutdown'].astype(int) >= i) &\n",
    "                                       (off_fut['commissioned'].astype(int) <= i), off_fut['capacity'], 0)\n",
    "    \n",
    "    '''assumptions:\n",
    "    40y lifetime for all heat only power plants\n",
    "    eaqual number of heat only power plants commissioned each year\n",
    "    new builds after 2017 are not considered\n",
    "    '''\n",
    "    \n",
    "    if i <= 2017 :\n",
    "        ho['{}'.format(i)] = ho['capacity'] * (1 - ((2017 - i) / 40))\n",
    "    elif 2017 < i <= 2017 + 40 :\n",
    "        ho['{}'.format(i)] = ho['capacity'] * (1 - ((i - 2017) / 40))\n",
    "    else :\n",
    "        ho['{}'.format(i)] = 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hydro powerplants have no shutdown\n",
    "for i in years:\n",
    "    con['{}'.format(i)] = np.where((con['balmorel_tec_group'] == 'RES') |\n",
    "                                   (con['balmorel_tec_group'] == 'ROR'),\n",
    "                                   con['capacity'],\n",
    "                                   con['{}'.format(i)]).round(decimals=5)\n",
    "    \n",
    "    ren['{}'.format(i)] = np.where(ren['balmorel_tec_group'] == 'ROR',\n",
    "                                   ren['capacity'],\n",
    "                                   ren['{}'.format(i)]).round(decimals=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary Storing of Dataframes\n",
    "The translated dataframes will be saved temporily as pickle files, to quickly store the python objects. This allows for fast re-aggregation. Re-run all the following steps starting at *Aggregation* with a any aggragation choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create pickle directory\n",
    "if not os.path.isdir('pickles'):\n",
    "    os.makedirs('pickles')\n",
    "\n",
    "# Save dataframes to pickle\n",
    "con.to_pickle('pickles/con_DE.pickle')\n",
    "ren.to_pickle('pickles/ren_DE.pickle')\n",
    "off_fut.to_pickle('pickles/off_fut_DE.pickle')\n",
    "ho.to_pickle('pickles/ho_DE.pickle')\n",
    "dh.to_pickle('pickles/dh_DE.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region: CHOOSE THE AGGREGATION FOR GERMAN REGIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a spatial resolution choice, with DE1 as the lowest and DE18 as the highest possible\n",
    "# The grid regions take grid bottlenecks into consideration\n",
    "# REGION CHOICE: \n",
    "region_choice = 'balmorel_DE4' # Possibilities: balmorel_DE1, balmorel_DE4, balmorel_DE5, balmorel_DE18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dataframes from pickle\n",
    "con = pd.read_pickle('pickles/con_DE.pickle')\n",
    "ren = pd.read_pickle('pickles/ren_DE.pickle')\n",
    "off_fut = pd.read_pickle('pickles/off_fut_DE.pickle')\n",
    "ho = pd.read_pickle('pickles/ho_DE.pickle')\n",
    "dh = pd.read_pickle('pickles/dh_DE.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make region aggregation dictionary\n",
    "dict_region_agg = region_agg[['grid_id', region_choice]].set_index('grid_id')[region_choice].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace in the balmorel_region column the grid_id by the balmorel region\n",
    "con = con.assign(balmorel_region = con.loc[:,'balmorel_region'].map(lambda x: dict_region_agg.get(x, x)))\n",
    "ren = ren.assign(balmorel_region = ren.loc[:,'balmorel_region'].map(lambda x: dict_region_agg.get(x, x)))\n",
    "off_fut = off_fut.assign(balmorel_region = off_fut.loc[:,'balmorel_region'].map(lambda x: dict_region_agg.get(x, x)))\n",
    "ho = ho.assign(balmorel_region = ho.loc[:,('balmorel_region','')].map(lambda x: dict_region_agg.get(x, x)))\n",
    "dh = dh.assign(balmorel_region = dh.loc[:,'balmorel_region'].map(lambda x: dict_region_agg.get(x, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output: District Heating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean-up for output\n",
    "dh = dh.groupby(['balmorel_region']).agg({'zip_dh_share': ['sum']})\n",
    "dh = dh.rename(index=str, columns={'zip_dh_share': 'dh_demand_TWh/a'})\n",
    "dh = pd.DataFrame(dh)\n",
    "dh[('dh_demand_share', '-')] =  dh['dh_demand_TWh/a'] / dh['dh_demand_TWh/a'].sum()\n",
    "dh = dh.round(2)\n",
    "\n",
    "# write dh table to csv file\n",
    "dh.to_csv('output/tables/dh_demand_{}.csv'.format(region_choice), encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency\n",
    "\n",
    "Powerplants of the same technology are aggregated in to groups, based on their efficiency class. The default interval length is set to 5%, but can be adjusted by a differen cluster choice. For renewable powerplants the efficiency is assumed to be one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EFFICIENCY CLUSTER CHOICE:\n",
    "eff_clu_choice = 0.05 # Possible values: (0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill missing data with '-', so it is kept throuout the grouping\n",
    "con['balmorel_tec_type'].fillna(value='-', inplace=True)\n",
    "ren['balmorel_tec_type'].fillna(value='-', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Efficiency_estimate: \"Proportion between power output and input, self researched values\"\n",
    "con['efficiency'] = con['efficiency_estimate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Groupby technology and fuel and assign the maximum and minimum efficiencies of each combination\n",
    "con['minimum'] = con.groupby(['balmorel_tec_group','balmorel_tec_type','balmorel_fuel'])['efficiency'].transform('min')\n",
    "con['maximum'] = con.groupby(['balmorel_tec_group','balmorel_tec_type','balmorel_fuel'])['efficiency'].transform('max')\n",
    "\n",
    "# Calculate the number of efficiency intervals based on the cluster choice\n",
    "con['eff_interval_n'] = round(((con.loc[:,'maximum'].round(2) - con.loc[:,'minimum'].round(2)) / eff_clu_choice) + 0.499, 0)\n",
    "con['eff_interval_n_copy'] = con['eff_interval_n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing data and assign the according efficiency interval to each single powerplant\n",
    "con.dropna(subset=['efficiency'], inplace=True)\n",
    "con.dropna(subset=['balmorel_fuel'], inplace=True)\n",
    "con = con.loc[con.capacity > 0]\n",
    "con['eff_interval'] = con.groupby(['balmorel_tec_group',\n",
    "                                   'balmorel_tec_type',\n",
    "                                   'balmorel_fuel',\n",
    "                                   'eff_interval_n'])[['efficiency']].transform(lambda x: \n",
    "                                                                                pd.cut(x, \n",
    "                                                                                       bins=con['eff_interval_n_copy'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renewable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fuel efficiency for renewables is set to 100%, after grouping efficiencies from opsd_con are copied, where appropriate\n",
    "ren['efficiency'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Offshore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fuel efficiency for offshore windturbines is set to 100%\n",
    "off_fut['efficiency'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping: Technology, Efficiency and Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Groupby region, technology, fuel and efficiency interval\n",
    "# Calculate the weighted mean interval efficiency and round to the 2nd decimal place\n",
    "weighted_mean = con.groupby(['balmorel_region',\n",
    "                             'balmorel_tec_group',\n",
    "                             'balmorel_tec_type',\n",
    "                             'balmorel_fuel',\n",
    "                             'eff_interval']).apply(lambda x:\n",
    "                                                    np.average(x['efficiency'],\n",
    "                                                               weights=x['capacity'])).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-arrange the grouped table back into a pandas dataframe \n",
    "weighted_mean = pd.DataFrame(weighted_mean, columns=['eff_w_mean'])\n",
    "weighted_mean.reset_index(inplace=True)\n",
    "\n",
    "# Merge opsd_con with weighted_mean\n",
    "con = con.merge(weighted_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a dictionary with the function to apply for a given column:\n",
    "y = {'{}'.format(i): ['sum'] for i in years}\n",
    "\n",
    "# Copy dataframes for intermediat output before grouping\n",
    "con_im = con\n",
    "ren_im = ren\n",
    "off_fut_im = off_fut\n",
    "ho_im = ho\n",
    "\n",
    "# Groupby and aggregate with your dictionary:\n",
    "con = con.groupby(['balmorel_region','balmorel_tec_group','balmorel_tec_type','balmorel_fuel','eff_interval','eff_w_mean']).agg(y)\n",
    "ren = ren.groupby(['balmorel_region','balmorel_tec_group','balmorel_tec_type','balmorel_fuel','efficiency']).agg(y)\n",
    "off_fut = off_fut.groupby(['balmorel_region','balmorel_tec_group','balmorel_tec_type','balmorel_fuel','efficiency']).agg(y)\n",
    "ho = ho.groupby(['balmorel_region','balmorel_fuel']).agg(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-arrange the grouped table back into a pandas dataframe \n",
    "con = pd.DataFrame(con)\n",
    "con.reset_index(inplace=True)\n",
    "\n",
    "ren = pd.DataFrame(ren)\n",
    "ren.reset_index(inplace=True)\n",
    "\n",
    "off_fut = pd.DataFrame(off_fut)\n",
    "off_fut.reset_index(inplace=True)\n",
    "\n",
    "ho = pd.DataFrame(ho)\n",
    "ho.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy efficiencies from opsd_con to opsd_ren, where the balmorel_technology name is identical\n",
    "# Group opsd_con by technology\n",
    "eff_con = con.groupby(['balmorel_tec_group','balmorel_tec_type']).agg({'eff_w_mean': ['mean']})\n",
    "\n",
    "# Create a new dataframe\n",
    "eff_con = pd.DataFrame(eff_con)\n",
    "eff_con.reset_index(inplace=True)\n",
    "eff_con.columns = eff_con.columns.droplevel(1)\n",
    "\n",
    "# Make a new column\n",
    "eff_con['balmorel_tec'] = eff_con.balmorel_tec_group + '_' + eff_con.balmorel_tec_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary from conventionale balmorel technology names to efficiencies\n",
    "dict_eff_con = eff_con.set_index(['balmorel_tec'])['eff_w_mean'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a new column in opsd_ren\n",
    "ren['eff_from_con'] = ren.balmorel_tec_group + '_' + ren.balmorel_tec_type\n",
    "\n",
    "# Apply the dict_eff_con\n",
    "ren = ren.assign(eff_from_con = ren.loc[:,'eff_from_con'].map(lambda x: dict_eff_con.get(x, x)))\n",
    "\n",
    "# Over-write the efficiencies with the eff_from_con, where eff_from_con is a number\n",
    "ren.efficiency = np.where(ren.eff_from_con.str.isdecimal() != False, ren.eff_from_con, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-Up for Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate output in the format:\n",
    "\n",
    "||balmorel_region|balmorel_fuel|capacity_sum|\n",
    "|:-----|:-----|-----:|------:|\n",
    "|opsd_con||||\n",
    "|opsd_ren||||\n",
    "|off_fut||||\n",
    "|ho||||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select relevant columns with index\n",
    "idx =  ['balmorel_region'] + ['balmorel_fuel'] + ['{}'.format(i) for i in years]\n",
    "\n",
    "# Trim dataframes by the index\n",
    "con_im = con_im[idx]\n",
    "ren_im = ren_im[idx]\n",
    "off_fut_im = off_fut_im[idx]\n",
    "ho_im = ho_im[idx]\n",
    "\n",
    "# Drop unnecessary column index\n",
    "ho_im.columns = ho_im.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe, where opsd_ren and heat only tables are appended to the conventional\n",
    "region_fuel_cap = con_im.append(ren_im, ignore_index=True)\n",
    "region_fuel_cap = region_fuel_cap.append(off_fut_im, ignore_index=True)\n",
    "region_fuel_cap = region_fuel_cap.append(ho_im, ignore_index=True)\n",
    "region_fuel_cap = region_fuel_cap.sort_values(['balmorel_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Groupby and aggregate with the dictionary\n",
    "region_fuel_cap = region_fuel_cap.groupby(['balmorel_region','balmorel_fuel']).agg(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-arrange the grouped table back into a pandas dataframe \n",
    "region_fuel_cap = pd.DataFrame(region_fuel_cap)\n",
    "region_fuel_cap.reset_index(inplace=True)\n",
    "\n",
    "# Round values, drop column level 1 and eliminate decimals\n",
    "region_fuel_cap = region_fuel_cap.round(0)\n",
    "region_fuel_cap.columns = region_fuel_cap.columns.droplevel(1)\n",
    "region_fuel_cap.loc[:, '2012':'2050'] = region_fuel_cap.loc[:, '2012':'2050'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write a csv file\n",
    "region_fuel_cap.to_csv('./output/tables/region_fuel_cap_{}.csv'.format(region_choice), encoding='utf8')\n",
    "\n",
    "# write a excel file\n",
    "region_fuel_cap.to_excel('./output/tables/region_fuel_cap_{}.xlsx'.format(region_choice), encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Fuel Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "% matplotlib inline\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "plt.rc('legend', fontsize=16)\n",
    "plt.rcParams['xtick.major.pad']='12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a dictionary from fuel to color\n",
    "color_dict = colors.set_index('balmorel_fuel')['opsd_color'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set new fuel names\n",
    "region_fuel_cap.loc[region_fuel_cap.balmorel_fuel=='Other fossil fuels', 'balmorel_fuel'] = 'Other'\n",
    "region_fuel_cap.loc[region_fuel_cap.balmorel_fuel=='ELEC', 'balmorel_fuel'] = 'HYDRO'\n",
    "region_fuel_cap.loc[region_fuel_cap.balmorel_fuel=='HEAT', 'balmorel_fuel'] = 'GEO/AIR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert MW to GW\n",
    "region_fuel_cap[region_fuel_cap.columns[2:]] = region_fuel_cap[region_fuel_cap.columns[2:]] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "DE_total_dev = region_fuel_cap.groupby(['balmorel_fuel']).agg(y)\n",
    "DE_total_dev.columns = DE_total_dev.columns.droplevel(1)\n",
    "DE_total_dev = DE_total_dev.transpose()\n",
    "DE_total_dev.columns.name = None\n",
    "\n",
    "# Plot\n",
    "DE_total_dev.plot.area(figsize=(16,9),\n",
    "                       lw=0,\n",
    "                       color=DE_total_dev.columns[:].map(lambda x: color_dict.get(x,x)),\n",
    "                       legend='reverse',\n",
    "                       stacked=True)\n",
    "\n",
    "plt.title('Exogenous Capacities DE, 2012-2050')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Energy [GW]')\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('output/figures/DE_fuel_dev.png', transparent=True, compression=None)\n",
    "plt.show()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot by regions\n",
    "for i in list(region_fuel_cap.balmorel_region.unique()):\n",
    "    plt.close()\n",
    "    DE_region_dev = region_fuel_cap[region_fuel_cap.balmorel_region==i].groupby(['balmorel_fuel']).agg(y)\n",
    "    DE_region_dev.columns = DE_region_dev.columns.droplevel(1)\n",
    "    DE_region_dev = DE_region_dev.transpose()\n",
    "    DE_region_dev.columns.name = None\n",
    "    DE_region_dev.plot.area(figsize=(16,9),\n",
    "                            lw=0,\n",
    "                            color=DE_region_dev.columns[:].map(lambda x: color_dict.get(x,x)),\n",
    "                            legend='reverse',\n",
    "                            stacked=True)\n",
    "    plt.ylim([0, region_fuel_cap.groupby(['balmorel_region']).agg(y).max(axis=1).max() * 1.1])\n",
    "    plt.title('Exogenous Capacities {}, 2012-2050'.format(i))\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Energy [GW]')\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('output/figures/{}_region_fuel_dev.png'.format(i), transparent=True, compression=None)\n",
    "    plt.show()\n",
    "    \n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "region_fuel_cap_2016 = region_fuel_cap.groupby(['balmorel_fuel'])['2016'].sum()\n",
    "region_fuel_cap_2016 = pd.DataFrame(region_fuel_cap_2016)\n",
    "region_fuel_cap_2016['colors'] = region_fuel_cap_2016.index\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "\n",
    "DE_2016_bar = plt.bar(region_fuel_cap_2016.index,\n",
    "                      region_fuel_cap_2016['2016'],\n",
    "                      color=region_fuel_cap_2016['colors'].map(lambda x: color_dict.get(x, x)))\n",
    "plt.title('DE, 2016')\n",
    "plt.xlabel('Fuel')\n",
    "plt.ylabel('Energy [GW]')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Save figure\n",
    "fig.savefig('output/figures/DE_2016_bar.png', transparent=True, compression=None)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "region_total_bar = region_fuel_cap.groupby(['balmorel_region', 'balmorel_fuel']).agg(y)\n",
    "region_total_bar.columns = region_total_bar.columns.droplevel(1)\n",
    "region_total_bar['colors'] = region_total_bar.index.get_level_values(1)\n",
    "region_total_bar = region_total_bar.assign(colors = region_total_bar.loc[:,'colors'].map(lambda x: color_dict.get(x,x)))\n",
    "\n",
    "# Specifications for each plot\n",
    "regions = region_total_bar.index.get_level_values('balmorel_region').unique()\n",
    "yr = '2016'\n",
    "\n",
    "# Create a folder for the graphs\n",
    "if not os.path.isdir('output/figures/' + region_choice):\n",
    "    os.makedirs('output/figures/' + region_choice)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for region,num in zip(regions, range(1,len(regions) + 1)):\n",
    "    plt.close()\n",
    "    ax = fig.add_subplot(len(regions),1,num)\n",
    "    df = region_total_bar.xs(region)[yr]\n",
    "    df = pd.DataFrame(df)\n",
    "    df['colors'] = df.index\n",
    "    plt.subplots(figsize=(16,9))\n",
    "    plt.bar(df.index,\n",
    "            df[yr],\n",
    "            color=df.colors.map(lambda x: color_dict.get(x, x)))\n",
    "    plt.xlabel('Fuel')\n",
    "    plt.ylabel('Energy [GW]')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(region + ', ' + yr)\n",
    "    plt.ylim([0,max(region_total_bar.max(axis=1)) * 1.1])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('output/figures/' + region_choice + '/region_' + region + '_2016_bar.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-Up for Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Formatting efficiency values and merging technology, fuel and counter into one column\n",
    "con['balmorel_eff'] = con['eff_w_mean'] * 100\n",
    "con['balmorel_eff'] = con['balmorel_eff'].astype(int)\n",
    "ren['balmorel_eff'] = ren['efficiency'] * 100\n",
    "ren['balmorel_eff'] = ren['balmorel_eff'].astype(int)\n",
    "off_fut['balmorel_eff'] = off_fut['efficiency'].astype(int) * 100\n",
    "ho_fuel['balmorel_eff'] = ho_fuel['average_efficiency_2017'] * 100\n",
    "ho_fuel['balmorel_eff'] = ho_fuel['balmorel_eff'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column names\n",
    "con['Technology'] = np.where((con['balmorel_tec_type'] != '-'),\n",
    "                             (con['balmorel_tec_group'] + '_' + con['balmorel_fuel'] + '_' +\n",
    "                              con['balmorel_tec_type'] + '_E-' + con['balmorel_eff'].map(str)),\n",
    "                             (con['balmorel_tec_group'] + '_' + con['balmorel_fuel'] +\n",
    "                              '_E-' + con['balmorel_eff'].map(str)))\n",
    "\n",
    "ren['Technology'] = np.where((ren['balmorel_tec_type'] != '-'),\n",
    "                             (ren['balmorel_tec_group'] + '_' + ren['balmorel_fuel'] + '_' +\n",
    "                              ren['balmorel_tec_type'] + '_E-' + ren['balmorel_eff'].map(str)),\n",
    "                             (ren['balmorel_tec_group'] + '_' + ren['balmorel_fuel'] +\n",
    "                              '_E-' + ren['balmorel_eff'].map(str)))\n",
    "\n",
    "off_fut['Technology'] = 'GNR_' + off_fut['balmorel_tec_group'] + '_' + off_fut['balmorel_fuel'] + '_' + off_fut['balmorel_tec_type']\n",
    "\n",
    "ho['Technology'] = 'GNR_' + 'BO_' + ho_fuel['balmorel_fuel'] + '_E-' + ho_fuel['balmorel_eff'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Renewable power plant efficiencies will not be containt in the technology name\n",
    "con['Technology'] = np.where((con.balmorel_fuel == 'WTR'),\n",
    "                             (con['Technology'].str.rsplit('_E', 1).str.get(0)),\n",
    "                             (con['Technology']))\n",
    "\n",
    "ren['Technology'] = np.where((ren.balmorel_fuel == 'SUN') |\n",
    "                             (ren.balmorel_fuel == 'WTR') |\n",
    "                             (ren.balmorel_fuel == 'WIND') |\n",
    "                             (ren.balmorel_fuel == 'ELEC') |\n",
    "                             (ren.balmorel_tec_group == 'GEO'),\n",
    "                             (ren['Technology'].str.rsplit('_E', 1).str.get(0)),\n",
    "                             (ren['Technology']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reservoirs with pumping and electrical storages get a specified name\n",
    "con['Technology'] = np.where((con.balmorel_tec_type == 'PMP'),\n",
    "                             ('AGG-' + con['balmorel_region'] + '_' + con['Technology']),\n",
    "                             ('GNR_' + con['Technology']))\n",
    "\n",
    "ren['Technology'] = np.where((ren.balmorel_tec_group == 'ES'),\n",
    "                             ('AGG-' + ren['balmorel_region'] + '_' + ren['Technology']),\n",
    "                             ('GNR_' + ren['Technology']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new columns for area and dot\n",
    "con['Area'] = con['balmorel_region']\n",
    "con[''] = '.'\n",
    "\n",
    "ren['Area'] = ren['balmorel_region']\n",
    "ren[''] = '.'\n",
    "\n",
    "off_fut['Area'] = off_fut['balmorel_region']\n",
    "off_fut[''] = '.'\n",
    "\n",
    "ho['Area'] = ho['balmorel_region']\n",
    "ho[''] = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select relevant columns with index\n",
    "idx =  ['Area'] + [''] + ['Technology'] + ['{}'.format(i) for i in years]\n",
    "\n",
    "con = con[idx]\n",
    "ren = ren[idx]\n",
    "off_fut = off_fut[idx]\n",
    "ho = ho[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe\n",
    "capacities_DE = con.append(ren, ignore_index=True)\n",
    "capacities_DE = capacities_DE.append(off_fut, ignore_index=True)\n",
    "capacities_DE = capacities_DE.append(ho, ignore_index=True)\n",
    "capacities_DE = capacities_DE.sort_values(['Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign new areas to the offshore capacities\n",
    "capacities_DE['Area'] = np.where(capacities_DE['Technology'].str.contains('OFF')==True,\n",
    "                                 capacities_DE['Area'].astype(str) + '_Offshore',\n",
    "                                 capacities_DE['Area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G Output\n",
    "It contains all the unique technology names of capacities_DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select relevant columns for G with index\n",
    "idx_g = ['Technology']\n",
    "\n",
    "# Create new dataframes with index\n",
    "DE_G = capacities_DE[idx_g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort by technology names, drop duplicates and reset the index\n",
    "DE_G = DE_G.sort_values(['Technology'])\n",
    "DE_G.drop_duplicates(subset=['Technology'], inplace=True)\n",
    "DE_G.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write DE_G to csv file\n",
    "DE_G.to_csv('output/tables/DE_G.csv', encoding='utf8')\n",
    "\n",
    "# Write DE_G to xls file\n",
    "DE_G.to_excel('output/tables/DE_G.xlsx', encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GKFX Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append an 'A' to the Area name tail\n",
    "capacities_DE['Area'] = capacities_DE['Area'].astype(str) + '_A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Round capacities to requiered number of decimal places\n",
    "decimal_choice = 2\n",
    "capacities_DE = capacities_DE.round(decimal_choice)\n",
    "capacities_DE.columns = capacities_DE.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum an d aggregate capacities\n",
    "capacities_DE = capacities_DE.groupby(['Area','','Technology']).agg(y)\n",
    "capacities_DE = pd.DataFrame(capacities_DE)\n",
    "capacities_DE.reset_index(inplace=True)\n",
    "capacities_DE.columns = capacities_DE.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a csv file\n",
    "capacities_DE.to_csv('./output/tables/DE_GKFX_{}.csv'.format(region_choice), encoding='utf8')\n",
    "\n",
    "# Write a excel file\n",
    "capacities_DE.to_excel('./output/tables/DE_GKFX_{}.xlsx'.format(region_choice), encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCC, RRR, AAA Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new dataframe for CCC, RRR, AAA output\n",
    "geography = capacities_DE[['Technology','Area']]\n",
    "geography['region'] = capacities_DE['Area'].str.split('_').str.get(0)\n",
    "geography = geography.rename(index=str, columns={'Technology': 'CCC', 'region': 'RRR','Area': 'AAA'})\n",
    "geography.loc[:,'CCC']='GERMANY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AAA\n",
    "AAA = geography[['AAA']]\n",
    "AAA = AAA.drop_duplicates()\n",
    "AAA.to_csv('output/tables/AAA_DE.csv', encoding='utf8')\n",
    "AAA.to_excel('output/tables/AAA_DE.xlsx', encoding='utf8')\n",
    "\n",
    "# RRR\n",
    "RRR = geography[['RRR']]\n",
    "RRR = RRR.drop_duplicates()\n",
    "RRR.to_csv('output/tables/RRR_DE.csv', encoding='utf8')\n",
    "RRR.to_excel('output/tables/RRR_DE.xlsx', encoding='utf8')\n",
    "\n",
    "# CCC\n",
    "CCC = geography[['CCC']]\n",
    "CCC = CCC.drop_duplicates()\n",
    "CCC.to_csv('output/tables/CCC_DE.csv', encoding='utf8')\n",
    "CCC.to_excel('output/tables/CCC_DE.xlsx', encoding='utf8')\n",
    "\n",
    "# RRRAAA\n",
    "RRRAAA = geography[['RRR','AAA']]\n",
    "RRRAAA = RRRAAA.drop_duplicates()\n",
    "RRRAAA.to_csv('output/tables/RRRAAA_DE.csv', encoding='utf8')\n",
    "RRRAAA.to_excel('output/tables/RRRAAA_DE.xlsx', encoding='utf8')\n",
    "\n",
    "# CCCRRR\n",
    "CCCRRR = geography[['CCC','RRR']]\n",
    "CCCRRR = CCCRRR.drop_duplicates()\n",
    "CCCRRR.to_csv('output/tables/CCCRRR_DE.csv', encoding='utf8')\n",
    "CCCRRR.to_excel('output/tables/CCCRRR_DE.xlsx', encoding='utf8')\n",
    "\n",
    "# CCCRRRAAA\n",
    "CCCRRRAAA = pd.Series(geography.values.ravel('F'))\n",
    "CCCRRRAAA = CCCRRRAAA.drop_duplicates()\n",
    "CCCRRRAAA.to_csv('output/tables/CCCRRRAAA_DE.csv', encoding='utf8')\n",
    "CCCRRRAAA.to_excel('output/tables/CCCRRRAAA_DE.xlsx', encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check summed capacities\n",
    "In order to verify, whether the results of the data processing are in a reasonable range, the yearly stacked generation capacities are compared to three other sources:\n",
    "1. bnatza values, which are the summed capacities of opsd_con and opsd_ren (upper boundary)\n",
    "2. flex4res values, which are supposed to be replaced\n",
    "3. opsd national generation capacity values, which are from the same source as opsd_con and opsd_ren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read plotting data\n",
    "Raw data on national generation capacities available here: https://data.open-power-system-data.org/national_generation_capacity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read stacked capacities from the flex4res and the national generation capacities table\n",
    "capacity_comparison = pd.read_csv('input/cap_comparison.csv',\n",
    "                      encoding='utf8',\n",
    "                      header=0,\n",
    "                      index_col=0)\n",
    "\n",
    "# Re-read the original opsd_con table\n",
    "con_orig = pd.read_csv('input/conventionals.csv',\n",
    "                      encoding='utf8',\n",
    "                      header=0)\n",
    "\n",
    "# Re-read the original opsd_ren table\n",
    "ren_orig = pd.read_csv('input/renewables.csv',\n",
    "                      encoding='utf8',\n",
    "                      header=0,\n",
    "                      parse_dates=[1],\n",
    "                      low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean-Up for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "capacities_DE.drop(['', 'Area'], axis=1, inplace=True)\n",
    "\n",
    "# Select the technology column as the new index\n",
    "capacities_DE.set_index('Technology', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a folder for the graphs\n",
    "if not os.path.isdir('output/figures/cap_comparison/'):\n",
    "    os.makedirs('output/figures/cap_comparison/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sum the yearly capacities and/or re-naming the data sets\n",
    "capacities_DE_stacked = capacities_DE.sum(axis=0) / 1000\n",
    "\n",
    "bnetza_2015 = (ren_orig['electrical_capacity'].sum() +\n",
    "               ren_orig['thermal_capacity'].sum() +\n",
    "               con_orig['capacity_net_bnetza'].sum()) / 1000\n",
    "\n",
    "capacities_flex4res = capacity_comparison['Flex4Res'] / 1000\n",
    "\n",
    "opsd_national_stacked = capacity_comparison.opsd / 1000\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "plt.plot(years, opsd_national_stacked, label='opsd_DE_stacked')\n",
    "plt.plot(years, capacities_flex4res, label='f4r')\n",
    "plt.plot(years, capacities_DE_stacked, label='capacities_DE_stacked')\n",
    "plt.hlines(y=bnetza_2015, xmin=2012, xmax=2050, colors='r', linestyles='--', label='bnetza, 2015')\n",
    "plt.legend(loc=3)\n",
    "plt.title('All fuels, stacked')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Energy [GW]')\n",
    "plt.ylim([0,320])\n",
    "plt.show()\n",
    "\n",
    "# save figure\n",
    "fig.savefig('output/figures/cap_comparison/comparison_all.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check capacities per fuel\n",
    "Comparing fuel specific generation capacities between the opsd data and data from the flex4res table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import of fuel specific generation capacities of flex4res\n",
    "fuel_capacities_flex4res = pd.read_csv('input/cap_comparison_flex4res.csv',\n",
    "                                      header=0,\n",
    "                                      encoding='utf8')\n",
    "\n",
    "# Adjusting the dataframe\n",
    "fuel_capacities_flex4res.set_index('Technology', inplace=True)\n",
    "fuel_capacities_flex4res.index.astype(str);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIOGAS/WOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "plt.plot(years[0:19], fuel_capacities_flex4res[fuel_capacities_flex4res.index.str.contains('WOOD')].sum(), label='f4r')\n",
    "plt.plot(years, capacities_DE[capacities_DE.index.str.contains('BGAS')].sum(), label='opsd')\n",
    "plt.legend(loc=3)\n",
    "plt.title('Biogas/Wood')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Energy [MW]')\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "fig.savefig('output/figures/cap_comparison/comparison_BGAS.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filter\n",
    "searchfor = ['COAL', 'LIGNITE']\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "plt.plot(years[0:19],\n",
    "         fuel_capacities_flex4res[fuel_capacities_flex4res.index.str.contains('|'.join(searchfor))].sum() / 1000,\n",
    "         label='f4r')\n",
    "plt.plot(years, capacities_DE[capacities_DE.index.str.contains('COAL|LIGN')].sum() / 1000, label='opsd')\n",
    "plt.legend(loc=3)\n",
    "plt.title('Coal/Lignite')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Energy [GW]')\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "fig.savefig('output/figures/cap_comparison/comparison_COAL.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FUELOIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "plt.plot(years[0:19],\n",
    "         fuel_capacities_flex4res[fuel_capacities_flex4res.index.str.contains('FUELOIL')].sum() / 1000,\n",
    "         label='f4r')\n",
    "plt.plot(years,\n",
    "         capacities_DE[capacities_DE.index.str.contains('FUELOIL')].sum() / 1000,\n",
    "         label='opsd')\n",
    "plt.legend(loc=3)\n",
    "plt.title('Oil')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Energy [GW]')\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "fig.savefig('output/figures/cap_comparison/comparison_FUELOIL.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MUNIWASTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "plt.plot(years[0:19],\n",
    "         fuel_capacities_flex4res[fuel_capacities_flex4res.index.str.contains('MUNIWASTE')].sum() / 1000,\n",
    "         label='f4r')\n",
    "plt.plot(years,\n",
    "         capacities_DE[capacities_DE.index.str.contains('MSW')].sum() / 1000,\n",
    "         label='opsd')\n",
    "plt.legend(loc=3)\n",
    "plt.title('Waste')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Energy [GW]')\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "fig.savefig('output/figures/cap_comparison/comparison_MSW.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NATGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "plt.plot(years[0:19],\n",
    "         fuel_capacities_flex4res[fuel_capacities_flex4res.index.str.contains('NATGAS')].sum() / 1000,\n",
    "         label='f4r')\n",
    "plt.plot(years,\n",
    "         capacities_DE[capacities_DE.index.str.contains('NGAS')].sum() / 1000,\n",
    "         label='opsd')\n",
    "plt.legend(loc=3)\n",
    "plt.title('Natural gas')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Energy [GW]')\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "fig.savefig('output/figures/cap_comparison/comparison_NGAS.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NUCLEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "plt.plot(years[0:19],\n",
    "         fuel_capacities_flex4res[fuel_capacities_flex4res.index.str.contains('NUCLEAR')].sum() / 1000,\n",
    "         label='f4r')\n",
    "plt.plot(years,\n",
    "         capacities_DE[capacities_DE.index.str.contains('NUCL')].sum() / 1000,\n",
    "         label='opsd')\n",
    "plt.legend(loc=3)\n",
    "plt.title('Nuclear')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Energy [GW]')\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "fig.savefig('output/figures/cap_comparison/comparison_NUCL.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "plt.plot(years[0:19],\n",
    "         fuel_capacities_flex4res[fuel_capacities_flex4res.index.str.contains('SUN')].sum() / 1000,\n",
    "         label='f4r')\n",
    "plt.plot(years,\n",
    "         capacities_DE[capacities_DE.index.str.contains('SUN')].sum() / 1000,\n",
    "         label='opsd')\n",
    "plt.legend(loc=3)\n",
    "plt.title('Sun')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Energy [GW]')\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "fig.savefig('output/figures/cap_comparison/comparison_SUN.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "plt.plot(years[0:19],\n",
    "         fuel_capacities_flex4res[fuel_capacities_flex4res.index.str.contains('WATER')].sum() / 1000,\n",
    "         label='f4r')\n",
    "plt.plot(years,\n",
    "         capacities_DE[capacities_DE.index.str.contains('WTR|PMP')].sum() / 1000,\n",
    "         label='opsd')\n",
    "plt.legend(loc=4)\n",
    "plt.title('Water')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Energy [GW]')\n",
    "plt.ylim([0,60])\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "fig.savefig('output/figures/cap_comparison/comparison_WTR.pdf')\n",
    "\n",
    "# comment: comparing MW (f4r) and MWh (opsd)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WIND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "plt.plot(years[0:19],\n",
    "         fuel_capacities_flex4res[fuel_capacities_flex4res.index.str.contains('WIND')].sum() / 1000,\n",
    "         label='f4r')\n",
    "plt.plot(years,\n",
    "         capacities_DE[capacities_DE.index.str.contains('WIND')].sum() / 1000,\n",
    "         label='opsd')\n",
    "plt.legend(loc=3)\n",
    "plt.title('Wind')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Energy [GW]')\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "fig.savefig('output/figures/cap_comparison/comparison_WIND.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GEOTHERMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "plt.plot(years[0:19],\n",
    "         fuel_capacities_flex4res[fuel_capacities_flex4res.index.str.contains('GEO')].sum() / 1000,\n",
    "         label='f4r')\n",
    "plt.plot(years,\n",
    "         capacities_DE[capacities_DE.index.str.contains('GEO')].sum() / 1000,\n",
    "         label='opsd')\n",
    "plt.legend(loc=3)\n",
    "plt.title('Geothermal')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Energy [GW]')\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "fig.savefig('output/figures/cap_comparison/comparison_GEO.pdf')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
